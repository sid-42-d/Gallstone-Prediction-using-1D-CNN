{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtNVv3UiC-sQ",
        "outputId": "dde8343c-247b-4632-d10b-292c75da5113"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… All packages work!\n",
            "Pandas: 2.2.2\n",
            "NumPy: 2.0.2\n",
            "Scikit-learn: 1.6.1\n",
            "TensorFlow: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "# Test cell - Run this first\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import tensorflow\n",
        "\n",
        "print(\"âœ… All packages work!\")\n",
        "print(f\"Pandas: {pd.__version__}\")\n",
        "print(f\"NumPy: {np.__version__}\")\n",
        "print(f\"Scikit-learn: {sklearn.__version__}\")\n",
        "print(f\"TensorFlow: {tensorflow.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# LOAD CSV FROM GOOGLE DRIVE\n",
        "# ========================================\n",
        "\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"ðŸ“ Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"âœ… Drive mounted!\\n\")\n",
        "\n",
        "# ============================================\n",
        "# CONFIGURE YOUR FILE PATH HERE\n",
        "# ============================================\n",
        "FILE_PATH = '/content/drive/MyDrive/gallstone_data.csv'  # â¬…ï¸ CHANGE THIS TO YOUR FILE PATH\n",
        "\n",
        "# ============================================\n",
        "\n",
        "# Load the CSV file\n",
        "print(f\"ðŸ“‚ Loading file from: {FILE_PATH}\")\n",
        "print(\"â³ Reading CSV file...\\n\")\n",
        "\n",
        "df = pd.read_csv(FILE_PATH)\n",
        "\n",
        "# Clean the data\n",
        "df = df.dropna(how='all')  # Remove completely empty rows\n",
        "df = df.dropna(axis=1, how='all')  # Remove completely empty columns\n",
        "df.columns = [str(col).strip() for col in df.columns]  # Clean column names\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ðŸŽ‰ SUCCESS! DATA LOADED FROM DRIVE!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"Shape: {df.shape[0]} rows Ã— {df.shape[1]} columns\")\n",
        "print(f\"\\nðŸ“‹ Columns:\")\n",
        "print(df.columns.tolist())\n",
        "print(f\"\\nðŸ“Š First 5 rows:\")\n",
        "print(df.head())\n",
        "print(f\"\\nðŸ“Š Data types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"âœ… Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfS4mvcJDEZ_",
        "outputId": "f2e937df-177a-456c-fb8b-bb4db9a4acce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "âœ… Drive mounted!\n",
            "\n",
            "ðŸ“‚ Loading file from: /content/drive/MyDrive/gallstone_data.csv\n",
            "â³ Reading CSV file...\n",
            "\n",
            "============================================================\n",
            "ðŸŽ‰ SUCCESS! DATA LOADED FROM DRIVE!\n",
            "============================================================\n",
            "Shape: 319 rows Ã— 39 columns\n",
            "\n",
            "ðŸ“‹ Columns:\n",
            "['Gallstone Status', 'Age', 'Gender', 'Comorbidity', 'Coronary Artery Disease (CAD)', 'Hypothyroidism', 'Hyperlipidemia', 'Diabetes Mellitus (DM)', 'Height', 'Weight', 'Body Mass Index (BMI)', 'Total Body Water (TBW)', 'Extracellular Water (ECW)', 'Intracellular Water (ICW)', 'Extracellular Fluid/Total Body Water (ECF/TBW)', 'Total Body Fat Ratio (TBFR) (%)', 'Lean Mass (LM) (%)', 'Body Protein Content (Protein) (%)', 'Visceral Fat Rating (VFR)', 'Bone Mass (BM)', 'Muscle Mass (MM)', 'Obesity (%)', 'Total Fat Content (TFC)', 'Visceral Fat Area (VFA)', 'Visceral Muscle Area (VMA) (Kg)', 'Hepatic Fat Accumulation (HFA)', 'Glucose', 'Total Cholesterol (TC)', 'Low Density Lipoprotein (LDL)', 'High Density Lipoprotein (HDL)', 'Triglyceride', 'Aspartat Aminotransferaz (AST)', 'Alanin Aminotransferaz (ALT)', 'Alkaline Phosphatase (ALP)', 'Creatinine', 'Glomerular Filtration Rate (GFR)', 'C-Reactive Protein (CRP)', 'Hemoglobin (HGB)', 'Vitamin D']\n",
            "\n",
            "ðŸ“Š First 5 rows:\n",
            "   Gallstone Status  Age  Gender  Comorbidity  Coronary Artery Disease (CAD)  \\\n",
            "0                 0   50       0            0                              0   \n",
            "1                 0   47       0            1                              0   \n",
            "2                 0   61       0            0                              0   \n",
            "3                 0   41       0            0                              0   \n",
            "4                 0   42       0            0                              0   \n",
            "\n",
            "   Hypothyroidism  Hyperlipidemia  Diabetes Mellitus (DM)  Height  Weight  \\\n",
            "0               0               0                       0     185    92.8   \n",
            "1               0               0                       0     176    94.5   \n",
            "2               0               0                       0     171    91.1   \n",
            "3               0               0                       0     168    67.7   \n",
            "4               0               0                       0     178    89.6   \n",
            "\n",
            "   ...  High Density Lipoprotein (HDL)  Triglyceride  \\\n",
            "0  ...                            40.0         134.0   \n",
            "1  ...                            43.0         103.0   \n",
            "2  ...                            43.0          69.0   \n",
            "3  ...                            59.0          53.0   \n",
            "4  ...                            30.0         326.0   \n",
            "\n",
            "   Aspartat Aminotransferaz (AST)  Alanin Aminotransferaz (ALT)  \\\n",
            "0                            20.0                          22.0   \n",
            "1                            14.0                          13.0   \n",
            "2                            18.0                          14.0   \n",
            "3                            20.0                          12.0   \n",
            "4                            27.0                          54.0   \n",
            "\n",
            "   Alkaline Phosphatase (ALP)  Creatinine  Glomerular Filtration Rate (GFR)  \\\n",
            "0                        87.0        0.82                            112.47   \n",
            "1                        46.0        0.87                            107.10   \n",
            "2                        66.0        1.25                             65.51   \n",
            "3                        34.0        1.02                             94.10   \n",
            "4                        71.0        0.82                            112.47   \n",
            "\n",
            "   C-Reactive Protein (CRP)  Hemoglobin (HGB)  Vitamin D  \n",
            "0                       0.0              16.0       33.0  \n",
            "1                       0.0              14.4       25.0  \n",
            "2                       0.0              16.2       30.2  \n",
            "3                       0.0              15.4       35.4  \n",
            "4                       0.0              16.8       40.6  \n",
            "\n",
            "[5 rows x 39 columns]\n",
            "\n",
            "ðŸ“Š Data types:\n",
            "Gallstone Status                                    int64\n",
            "Age                                                 int64\n",
            "Gender                                              int64\n",
            "Comorbidity                                         int64\n",
            "Coronary Artery Disease (CAD)                       int64\n",
            "Hypothyroidism                                      int64\n",
            "Hyperlipidemia                                      int64\n",
            "Diabetes Mellitus (DM)                              int64\n",
            "Height                                              int64\n",
            "Weight                                            float64\n",
            "Body Mass Index (BMI)                             float64\n",
            "Total Body Water (TBW)                            float64\n",
            "Extracellular Water (ECW)                         float64\n",
            "Intracellular Water (ICW)                         float64\n",
            "Extracellular Fluid/Total Body Water (ECF/TBW)    float64\n",
            "Total Body Fat Ratio (TBFR) (%)                   float64\n",
            "Lean Mass (LM) (%)                                float64\n",
            "Body Protein Content (Protein) (%)                float64\n",
            "Visceral Fat Rating (VFR)                           int64\n",
            "Bone Mass (BM)                                    float64\n",
            "Muscle Mass (MM)                                  float64\n",
            "Obesity (%)                                       float64\n",
            "Total Fat Content (TFC)                           float64\n",
            "Visceral Fat Area (VFA)                           float64\n",
            "Visceral Muscle Area (VMA) (Kg)                   float64\n",
            "Hepatic Fat Accumulation (HFA)                      int64\n",
            "Glucose                                           float64\n",
            "Total Cholesterol (TC)                            float64\n",
            "Low Density Lipoprotein (LDL)                     float64\n",
            "High Density Lipoprotein (HDL)                    float64\n",
            "Triglyceride                                      float64\n",
            "Aspartat Aminotransferaz (AST)                    float64\n",
            "Alanin Aminotransferaz (ALT)                      float64\n",
            "Alkaline Phosphatase (ALP)                        float64\n",
            "Creatinine                                        float64\n",
            "Glomerular Filtration Rate (GFR)                  float64\n",
            "C-Reactive Protein (CRP)                          float64\n",
            "Hemoglobin (HGB)                                  float64\n",
            "Vitamin D                                         float64\n",
            "dtype: object\n",
            "âœ… Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# GALLSTONE ML ANALYSIS - COMPLETE PIPELINE\n",
        "# ========================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import (confusion_matrix, accuracy_score, precision_score,\n",
        "                             recall_score, f1_score, roc_curve, roc_auc_score)\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"GALLSTONE PREDICTION - MACHINE LEARNING ANALYSIS\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdOX27-3DPI8",
        "outputId": "fdb4b147-260c-4b05-b8e0-7610a9316bbd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "GALLSTONE PREDICTION - MACHINE LEARNING ANALYSIS\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nDataset Shape: {df.shape}\")\n",
        "print(f\"Target Variable: Gallstone Status\")\n",
        "print(f\"  - 0: Gallstone Present\")\n",
        "print(f\"  - 1: No Gallstone\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvTImg_DDbZC",
        "outputId": "b6703994-1067-4b6b-a3bc-280d4d903da9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset Shape: (319, 39)\n",
            "Target Variable: Gallstone Status\n",
            "  - 0: Gallstone Present\n",
            "  - 1: No Gallstone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# DATA PREPROCESSING\n",
        "# ========================================\n",
        "print(\"\\nðŸ”§ Preprocessing data...\")\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Gallstone Status', axis=1)\n",
        "y = df['Gallstone Status']\n",
        "\n",
        "print(f\"  - Features: {X.shape[1]} columns\")\n",
        "print(f\"  - Samples: {X.shape[0]} rows\")\n",
        "print(f\"  - Class distribution:\")\n",
        "print(y.value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXIuCWcBDeVn",
        "outputId": "64bc8240-de9a-4355-a518-5e404e768591"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”§ Preprocessing data...\n",
            "  - Features: 38 columns\n",
            "  - Samples: 319 rows\n",
            "  - Class distribution:\n",
            "Gallstone Status\n",
            "0    161\n",
            "1    158\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First split: Train+Val vs Test (75% vs 25%)\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Second split: Train vs Val (80% vs 20% of trainval)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_trainval, y_trainval, test_size=0.2, random_state=42, stratify=y_trainval\n",
        ")\n",
        "\n",
        "print(f\"  - Training: {X_train.shape[0]} samples\")\n",
        "print(f\"  - Validation: {X_val.shape[0]} samples\")\n",
        "print(f\"  - Testing: {X_test.shape[0]} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR0LEtixIftg",
        "outputId": "5cc168f3-0057-48de-9170-3d8e0220efd4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - Training: 191 samples\n",
            "  - Validation: 48 samples\n",
            "  - Testing: 80 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# NORMALIZATION\n",
        "# ========================================\n",
        "print(\"\\nðŸ“Š Applying Normalization...\")\n",
        "\n",
        "# Z-Score\n",
        "scaler_zscore = StandardScaler()\n",
        "X_train_zscore = scaler_zscore.fit_transform(X_train)\n",
        "X_test_zscore = scaler_zscore.transform(X_test)\n",
        "\n",
        "# Min-Max\n",
        "scaler_minmax = MinMaxScaler()\n",
        "X_train_minmax = scaler_minmax.fit_transform(X_train)\n",
        "X_test_minmax = scaler_minmax.transform(X_test)\n",
        "\n",
        "print(\"  âœ“ Z-Score normalization applied\")\n",
        "print(\"  âœ“ Min-Max normalization applied\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2-tX05WDkBA",
        "outputId": "d50cac9f-fdb7-4ec0-cfee-629e05746a10"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Applying Normalization...\n",
            "  âœ“ Z-Score normalization applied\n",
            "  âœ“ Min-Max normalization applied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# INITIALIZE STORAGE\n",
        "# ========================================\n",
        "results = {\n",
        "    'Model': [], 'Normalization': [], 'Accuracy': [],\n",
        "    'Precision': [], 'Recall': [], 'F1-Score': [], 'ROC-AUC': []\n",
        "}\n",
        "confusion_matrices = {}\n",
        "roc_curves = {}"
      ],
      "metadata": {
        "id": "oysURA8rDum4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# TRAIN MODELS - MIN-MAX\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸŸ¢ MIN-MAX NORMALIZATION MODELS\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F3eA0TuDxob",
        "outputId": "a1b70279-f89b-4720-ec8a-482367f668f5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1D CNN\n",
        "print(\"\\n4ï¸âƒ£  1D CNN...\")\n",
        "X_train_cnn = X_train_minmax.reshape(X_train_minmax.shape[0], X_train_minmax.shape[1], 1)\n",
        "X_test_cnn = X_test_minmax.reshape(X_test_minmax.shape[0], X_test_minmax.shape[1], 1)\n",
        "\n",
        "cnn = Sequential([\n",
        "    Conv1D(64, 3, activation='relu', input_shape=(X_train_minmax.shape[1], 1)),\n",
        "    Conv1D(32, 3, activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "cnn.fit(X_train_cnn, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
        "\n",
        "y_proba = cnn.predict(X_test_cnn, verbose=0).ravel()\n",
        "y_pred = (y_proba > 0.5).astype(int)\n",
        "\n",
        "results['Model'].append('1D CNN')\n",
        "results['Normalization'].append('Min-Max')\n",
        "results['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
        "results['Precision'].append(precision_score(y_test, y_pred))\n",
        "results['Recall'].append(recall_score(y_test, y_pred))\n",
        "results['F1-Score'].append(f1_score(y_test, y_pred))\n",
        "results['ROC-AUC'].append(roc_auc_score(y_test, y_proba))\n",
        "confusion_matrices['1D CNN (Min-Max)'] = confusion_matrix(y_test, y_pred)\n",
        "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "roc_curves['1D CNN'] = (fpr, tpr, results['ROC-AUC'][-1])\n",
        "print(f\"   Accuracy: {results['Accuracy'][-1]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyCbX2fqD55S",
        "outputId": "2cd34252-cd31-4c35-f35d-0b500eb9bf0f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "4ï¸âƒ£  1D CNN...\n",
            "   Accuracy: 0.8250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# CORRECT CNN HYPERPARAMETER TUNING\n",
        "# ========================================\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "zgdE5mzmGbdl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 1: PROPER DATA SPLITTING\n",
        "# ========================================\n",
        "print(\"ðŸ“Š Splitting data properly...\")\n",
        "\n",
        "# First split: Train+Val vs Test (75% vs 25%)\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Second split: Train vs Val (80% vs 20% of trainval)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_trainval, y_trainval, test_size=0.2, random_state=42, stratify=y_trainval\n",
        ")\n",
        "\n",
        "print(f\"  - Training: {X_train.shape[0]} samples\")\n",
        "print(f\"  - Validation: {X_val.shape[0]} samples\")\n",
        "print(f\"  - Testing: {X_test.shape[0]} samples (NEVER TOUCHED UNTIL FINAL EVALUATION)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdhcO9WpIm_c",
        "outputId": "3258e94d-9b55-4c4d-f581-e43bfbbe8082"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Splitting data properly...\n",
            "  - Training: 191 samples\n",
            "  - Validation: 48 samples\n",
            "  - Testing: 80 samples (NEVER TOUCHED UNTIL FINAL EVALUATION)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 2: NORMALIZE DATA\n",
        "# ========================================\n",
        "print(\"\\nðŸ”§ Normalizing data...\")\n",
        "\n",
        "scaler_minmax = MinMaxScaler()\n",
        "X_train_norm = scaler_minmax.fit_transform(X_train)\n",
        "X_val_norm = scaler_minmax.transform(X_val)\n",
        "X_test_norm = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Reshape for CNN\n",
        "X_train_cnn = X_train_norm.reshape(X_train_norm.shape[0], X_train_norm.shape[1], 1)\n",
        "X_val_cnn = X_val_norm.reshape(X_val_norm.shape[0], X_val_norm.shape[1], 1)\n",
        "X_test_cnn = X_test_norm.reshape(X_test_norm.shape[0], X_test_norm.shape[1], 1)\n",
        "\n",
        "print(\"  âœ“ Data normalized and reshaped\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aizos0FvIsDX",
        "outputId": "65c0848c-9e69-4d79-9352-60b98bbfe771"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”§ Normalizing data...\n",
            "  âœ“ Data normalized and reshaped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 3: BUILD MODEL FUNCTION\n",
        "# ========================================\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # First Conv layer\n",
        "    model.add(Conv1D(\n",
        "        filters=hp.Int('conv1_filters', min_value=32, max_value=128, step=32),\n",
        "        kernel_size=hp.Choice('conv1_kernel', values=[2, 3, 5]),\n",
        "        activation='relu',\n",
        "        input_shape=(X_train_norm.shape[1], 1)\n",
        "    ))\n",
        "\n",
        "    # Second Conv layer\n",
        "    model.add(Conv1D(\n",
        "        filters=hp.Int('conv2_filters', min_value=16, max_value=64, step=16),\n",
        "        kernel_size=hp.Choice('conv2_kernel', values=[2, 3, 5]),\n",
        "        activation='relu'\n",
        "    ))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Dense layers\n",
        "    model.add(Dense(\n",
        "        units=hp.Int('dense1_units', min_value=32, max_value=128, step=32),\n",
        "        activation='relu'\n",
        "    ))\n",
        "    model.add(Dropout(hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "\n",
        "    model.add(Dense(\n",
        "        units=hp.Int('dense2_units', min_value=16, max_value=64, step=16),\n",
        "        activation='relu'\n",
        "    ))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Optimizer\n",
        "    lr = hp.Choice('learning_rate', values=[1e-4, 5e-4, 1e-3, 5e-3])\n",
        "    optimizer = Adam(learning_rate=lr)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "JPfwfuREIvxD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 4: HYPERPARAMETER TUNING\n",
        "# ========================================\n",
        "print(\"\\nðŸ” Starting hyperparameter tuning...\")\n",
        "print(\"  (This may take several minutes)\")\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=50,\n",
        "    factor=3,\n",
        "    directory='cnn_tuning',\n",
        "    project_name='gallstone_cnn_corrected',\n",
        "    overwrite=True  # Start fresh\n",
        ")\n",
        "\n",
        "# Early stopping to prevent overfitting\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# CORRECT: Use validation set (NOT test set!)\n",
        "tuner.search(\n",
        "    X_train_cnn, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_cnn, y_val),  # âœ“ CORRECT!\n",
        "    callbacks=[stop_early],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HjOut0sI3CA",
        "outputId": "151f453a-1bfe-4659-c195-0c5c3f62593e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 11s]\n",
            "val_accuracy: 0.8333333134651184\n",
            "\n",
            "Best val_accuracy So Far: 0.875\n",
            "Total elapsed time: 00h 11m 19s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 5: GET BEST HYPERPARAMETERS\n",
        "# ========================================\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ† BEST HYPERPARAMETERS FOUND\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Conv1 Filters: {best_hps.get('conv1_filters')}\")\n",
        "print(f\"Conv1 Kernel: {best_hps.get('conv1_kernel')}\")\n",
        "print(f\"Conv2 Filters: {best_hps.get('conv2_filters')}\")\n",
        "print(f\"Conv2 Kernel: {best_hps.get('conv2_kernel')}\")\n",
        "print(f\"Dense1 Units: {best_hps.get('dense1_units')}\")\n",
        "print(f\"Dense2 Units: {best_hps.get('dense2_units')}\")\n",
        "print(f\"Dropout: {best_hps.get('dropout')}\")\n",
        "print(f\"Learning Rate: {best_hps.get('learning_rate')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "810ynmRPI-In",
        "outputId": "f1814e75-a31d-4505-90fc-abdeafd36707"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ðŸ† BEST HYPERPARAMETERS FOUND\n",
            "============================================================\n",
            "Conv1 Filters: 64\n",
            "Conv1 Kernel: 3\n",
            "Conv2 Filters: 32\n",
            "Conv2 Kernel: 2\n",
            "Dense1 Units: 96\n",
            "Dense2 Units: 16\n",
            "Dropout: 0.30000000000000004\n",
            "Learning Rate: 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# STEP 6: TRAIN FINAL MODEL\n",
        "# ========================================\n",
        "print(\"\\nðŸš€ Training final model with best hyperparameters...\")\n",
        "\n",
        "# Combine train + val for final training\n",
        "X_trainval_norm = scaler_minmax.fit_transform(X_trainval)\n",
        "X_trainval_cnn = X_trainval_norm.reshape(X_trainval_norm.shape[0], X_trainval_norm.shape[1], 1)\n",
        "\n",
        "final_model = tuner.hypermodel.build(best_hps)\n",
        "history = final_model.fit(\n",
        "    X_trainval_cnn, y_trainval,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,  # 20% of trainval for monitoring\n",
        "    callbacks=[stop_early],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rA_rMbhJJ_H",
        "outputId": "4599a637-d6bf-460f-fe43-9c73cb605f92"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸš€ Training final model with best hyperparameters...\n",
            "Epoch 1/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.4947 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6914\n",
            "Epoch 2/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5697 - loss: 0.6849 - val_accuracy: 0.4792 - val_loss: 0.6920\n",
            "Epoch 3/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6851 - loss: 0.6667 - val_accuracy: 0.4792 - val_loss: 0.6908\n",
            "Epoch 4/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6540 - loss: 0.6581 - val_accuracy: 0.5000 - val_loss: 0.6860\n",
            "Epoch 5/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6297 - loss: 0.6375 - val_accuracy: 0.5000 - val_loss: 0.6871\n",
            "Epoch 6/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6218 - loss: 0.6403 - val_accuracy: 0.5000 - val_loss: 0.6795\n",
            "Epoch 7/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6465 - loss: 0.6183 - val_accuracy: 0.5208 - val_loss: 0.6734\n",
            "Epoch 8/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6576 - loss: 0.6073 - val_accuracy: 0.5833 - val_loss: 0.6481\n",
            "Epoch 9/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6688 - loss: 0.5787 - val_accuracy: 0.5625 - val_loss: 0.6331\n",
            "Epoch 10/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6974 - loss: 0.5880 - val_accuracy: 0.5833 - val_loss: 0.6169\n",
            "Epoch 11/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7114 - loss: 0.5455 - val_accuracy: 0.6458 - val_loss: 0.6018\n",
            "Epoch 12/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7359 - loss: 0.5375 - val_accuracy: 0.6667 - val_loss: 0.6048\n",
            "Epoch 13/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6958 - loss: 0.5497 - val_accuracy: 0.7500 - val_loss: 0.5771\n",
            "Epoch 14/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7005 - loss: 0.5618 - val_accuracy: 0.6875 - val_loss: 0.5712\n",
            "Epoch 15/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7516 - loss: 0.5449 - val_accuracy: 0.7500 - val_loss: 0.5311\n",
            "Epoch 16/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7585 - loss: 0.5088 - val_accuracy: 0.7708 - val_loss: 0.5101\n",
            "Epoch 17/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7476 - loss: 0.4830 - val_accuracy: 0.7917 - val_loss: 0.4917\n",
            "Epoch 18/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7650 - loss: 0.4659 - val_accuracy: 0.8125 - val_loss: 0.4980\n",
            "Epoch 19/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8324 - loss: 0.4397 - val_accuracy: 0.8333 - val_loss: 0.4704\n",
            "Epoch 20/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7791 - loss: 0.4414 - val_accuracy: 0.7917 - val_loss: 0.4677\n",
            "Epoch 21/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7582 - loss: 0.4458 - val_accuracy: 0.8125 - val_loss: 0.4741\n",
            "Epoch 22/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8023 - loss: 0.4435 - val_accuracy: 0.8125 - val_loss: 0.4335\n",
            "Epoch 23/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8373 - loss: 0.4095 - val_accuracy: 0.8125 - val_loss: 0.4430\n",
            "Epoch 24/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7354 - loss: 0.5073 - val_accuracy: 0.8542 - val_loss: 0.4070\n",
            "Epoch 25/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7533 - loss: 0.4930 - val_accuracy: 0.7917 - val_loss: 0.4439\n",
            "Epoch 26/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8228 - loss: 0.4081 - val_accuracy: 0.8750 - val_loss: 0.4266\n",
            "Epoch 27/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8594 - loss: 0.3959 - val_accuracy: 0.8750 - val_loss: 0.4049\n",
            "Epoch 28/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8076 - loss: 0.3918 - val_accuracy: 0.8542 - val_loss: 0.3993\n",
            "Epoch 29/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8485 - loss: 0.3786 - val_accuracy: 0.8750 - val_loss: 0.3829\n",
            "Epoch 30/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8023 - loss: 0.3939 - val_accuracy: 0.8750 - val_loss: 0.3858\n",
            "Epoch 31/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8112 - loss: 0.4050 - val_accuracy: 0.8958 - val_loss: 0.3796\n",
            "Epoch 32/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8501 - loss: 0.3865 - val_accuracy: 0.8750 - val_loss: 0.3903\n",
            "Epoch 33/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7894 - loss: 0.4227 - val_accuracy: 0.8333 - val_loss: 0.3902\n",
            "Epoch 34/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8576 - loss: 0.3398 - val_accuracy: 0.8750 - val_loss: 0.3693\n",
            "Epoch 35/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8399 - loss: 0.3432 - val_accuracy: 0.8958 - val_loss: 0.3595\n",
            "Epoch 36/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8372 - loss: 0.3566 - val_accuracy: 0.8333 - val_loss: 0.3656\n",
            "Epoch 37/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8871 - loss: 0.3035 - val_accuracy: 0.8750 - val_loss: 0.3536\n",
            "Epoch 38/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8683 - loss: 0.2962 - val_accuracy: 0.7917 - val_loss: 0.3845\n",
            "Epoch 39/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8764 - loss: 0.3215 - val_accuracy: 0.8750 - val_loss: 0.3369\n",
            "Epoch 40/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8320 - loss: 0.3307 - val_accuracy: 0.7917 - val_loss: 0.3812\n",
            "Epoch 41/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8858 - loss: 0.2763 - val_accuracy: 0.8750 - val_loss: 0.3419\n",
            "Epoch 42/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8901 - loss: 0.3002 - val_accuracy: 0.8542 - val_loss: 0.3563\n",
            "Epoch 43/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8639 - loss: 0.2705 - val_accuracy: 0.8333 - val_loss: 0.3568\n",
            "Epoch 44/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8324 - loss: 0.3619 - val_accuracy: 0.8333 - val_loss: 0.3706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#========================================\n",
        "# STEP 7: FINAL EVALUATION (FIRST TIME TOUCHING TEST SET!)\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“ˆ FINAL TEST SET EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "test_loss, test_acc = final_model.evaluate(X_test_cnn, y_test, verbose=0)\n",
        "y_pred_proba = final_model.predict(X_test_cnn, verbose=0).ravel()\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(f\"\\nâœ… Test Accuracy: {test_acc*100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "print(\"\\nðŸ“Š Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Gallstone', 'No Gallstone']))\n",
        "\n",
        "print(\"\\nðŸ”² Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpMVgTTkJObq",
        "outputId": "3be7442f-b91d-4206-95b9-6c9668c4b717"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ðŸ“ˆ FINAL TEST SET EVALUATION\n",
            "============================================================\n",
            "\n",
            "âœ… Test Accuracy: 85.00%\n",
            "Test Loss: 0.3728\n",
            "\n",
            "ðŸ“Š Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Gallstone       0.91      0.78      0.84        40\n",
            "No Gallstone       0.80      0.93      0.86        40\n",
            "\n",
            "    accuracy                           0.85        80\n",
            "   macro avg       0.86      0.85      0.85        80\n",
            "weighted avg       0.86      0.85      0.85        80\n",
            "\n",
            "\n",
            "ðŸ”² Confusion Matrix:\n",
            "[[31  9]\n",
            " [ 3 37]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ========================================\n",
        "# STEP 8: SAVE MODEL\n",
        "# ========================================\n",
        "final_model.save('best_gallstone_cnn_model.h5')\n",
        "print(\"\\nðŸ’¾ Model saved as 'best_gallstone_cnn_model.h5'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Frk4TKybJPd9",
        "outputId": "f9707086-2fe5-43e7-818e-185531d69dc0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ’¾ Model saved as 'best_gallstone_cnn_model.h5'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# VALIDATION CHECK\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ“ VALIDATION CHECKLIST\")\n",
        "print(\"=\"*60)\n",
        "print(\"âœ“ Test set was NOT used during hyperparameter tuning\")\n",
        "print(\"âœ“ Separate validation set was used for tuning\")\n",
        "print(\"âœ“ Final model trained on train+val data\")\n",
        "print(\"âœ“ Test set used ONLY for final evaluation\")\n",
        "print(\"âœ“ This is the CORRECT way to do hyperparameter tuning!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow-N4ZDhJUe9",
        "outputId": "3dd8cfb8-799b-4ce9-ef63-18033059cec8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "âœ“ VALIDATION CHECKLIST\n",
            "============================================================\n",
            "âœ“ Test set was NOT used during hyperparameter tuning\n",
            "âœ“ Separate validation set was used for tuning\n",
            "âœ“ Final model trained on train+val data\n",
            "âœ“ Test set used ONLY for final evaluation\n",
            "âœ“ This is the CORRECT way to do hyperparameter tuning!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W7Yp6sXFLvwk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}